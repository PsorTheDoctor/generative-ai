{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOK73IqYG9W2CyVnXzhTyPy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bd0056889a574ca193cbed0e790b63dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_757ed247a7e74e27a60feac2ee304c12",
              "IPY_MODEL_e4e09c5e49c44ea1885505d3acdbf2c3",
              "IPY_MODEL_81388268933a4ac5aa8714b9056cd8a6",
              "IPY_MODEL_56627e1a99a24c59b08559a61afc48b7"
            ],
            "layout": "IPY_MODEL_02321dbaea19437f970453923665d6fc"
          }
        },
        "757ed247a7e74e27a60feac2ee304c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c66939ebe170478f969baa521b4bc4d4",
            "placeholder": "​",
            "style": "IPY_MODEL_62dbc4b7966046878cd87477a5a70572",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "e4e09c5e49c44ea1885505d3acdbf2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b5b45c4aabcd42a39f0ef0a8cf10cdfe",
            "placeholder": "​",
            "style": "IPY_MODEL_0ee8137891934d198c8c93f65afc2e92",
            "value": ""
          }
        },
        "81388268933a4ac5aa8714b9056cd8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a7557b65c29e45b1974fc0a8bef535d5",
            "style": "IPY_MODEL_05a96d294e7f49b98885d6179abcb04c",
            "tooltip": ""
          }
        },
        "56627e1a99a24c59b08559a61afc48b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6f1b018f0ac49ef8fec518d7a2b256d",
            "placeholder": "​",
            "style": "IPY_MODEL_02bf1a54d5a34d01b74f36386d94fda7",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "02321dbaea19437f970453923665d6fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "c66939ebe170478f969baa521b4bc4d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62dbc4b7966046878cd87477a5a70572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5b45c4aabcd42a39f0ef0a8cf10cdfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee8137891934d198c8c93f65afc2e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7557b65c29e45b1974fc0a8bef535d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05a96d294e7f49b98885d6179abcb04c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f6f1b018f0ac49ef8fec518d7a2b256d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02bf1a54d5a34d01b74f36386d94fda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PsorTheDoctor/artificial-intelligence/blob/master/modern_approach/text_to_image/stable_diffusion_compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stable Diffusion image compression\n",
        "\n",
        "##Initial setup"
      ],
      "metadata": {
        "id": "SCGBhN7PasI8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGzrXBCGUzO3"
      },
      "outputs": [],
      "source": [
        "!pip install -qq diffusers[\"training\"] transformers ftfy\n",
        "!pip install -qq libimagequant\n",
        "!pip install -qq mozjpeg-lossless-optimization\n",
        "!pip install -qq scikit-image\n",
        "!pip install -qq Pillow==9.0.0 -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir input\n",
        "%mkdir output"
      ],
      "metadata": {
        "id": "QpUrYB0bC6--"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = '/content/input/'\n",
        "output_dir = '/content/output/'\n",
        "pretrained_model = 'CompVis/stable-diffusion-v1-4'"
      ],
      "metadata": {
        "id": "qfNv3P_NV5H6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299,
          "referenced_widgets": [
            "bd0056889a574ca193cbed0e790b63dc",
            "757ed247a7e74e27a60feac2ee304c12",
            "e4e09c5e49c44ea1885505d3acdbf2c3",
            "81388268933a4ac5aa8714b9056cd8a6",
            "56627e1a99a24c59b08559a61afc48b7",
            "02321dbaea19437f970453923665d6fc",
            "c66939ebe170478f969baa521b4bc4d4",
            "62dbc4b7966046878cd87477a5a70572",
            "b5b45c4aabcd42a39f0ef0a8cf10cdfe",
            "0ee8137891934d198c8c93f65afc2e92",
            "a7557b65c29e45b1974fc0a8bef535d5",
            "05a96d294e7f49b98885d6179abcb04c",
            "f6f1b018f0ac49ef8fec518d7a2b256d",
            "02bf1a54d5a34d01b74f36386d94fda7"
          ]
        },
        "id": "iI3-Cy2FXeH4",
        "outputId": "05a1ea1d-8440-4c74-d1d4-792bae6955f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import AutoencoderKL, UNet2DConditionModel, UNet2DModel, StableDiffusionImg2ImgPipeline\n",
        "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
        "from diffusers.schedulers import DDIMScheduler, LMSDiscreteScheduler, PNDMScheduler\n",
        "import torch\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\n",
        "    pretrained_model, subfolder=\"vae\", use_auth_token=True\n",
        ").to(device)\n",
        "\n",
        "unet = UNet2DConditionModel.from_pretrained(\n",
        "    pretrained_model, subfolder=\"unet\", use_auth_token=True\n",
        ").to(device)\n",
        "\n",
        "scheduler = PNDMScheduler(\n",
        "    beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\",\n",
        "    num_train_timesteps=1000, skip_prk_steps=True\n",
        ").set_format(\"pt\")\n",
        "\n",
        "text_encoder = CLIPTextModel.from_pretrained(\n",
        "    pretrained_model, subfolder=\"text_encoder\", use_auth_token=True\n",
        ")\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\n",
        "    pretrained_model, subfolder=\"tokenizer\", use_auth_token=True\n",
        ")\n",
        "uncond_input = tokenizer([\"\"], padding=\"max_length\", \n",
        "                         max_length=tokenizer.model_max_length, \n",
        "                         return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "  uncond_embeddings = text_encoder(uncond_input.input_ids)[0].to(device)"
      ],
      "metadata": {
        "id": "Gp5XdpqWZAuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Helper functions"
      ],
      "metadata": {
        "id": "RpyG7yE1adUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import inspect\n",
        "import io\n",
        "import libimagequant as liq\n",
        "import zlib\n",
        "import gc\n",
        "import time\n",
        "import mozjpeg_lossless_optimization\n",
        "from skimage.metrics import structural_similarity as get_ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as get_psnr\n",
        "\n",
        "@torch.no_grad()\n",
        "def to_latents(img: Image):\n",
        "  np_img = (np.array(img).astype(np.float32) / 255.0) * 2.0 - 1.0\n",
        "  np_img = np_img[None].transpose(0, 3, 1, 2)\n",
        "  torch_img = torch.from_numpy(np_img)\n",
        "  with autocast():\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(0)\n",
        "    latents = vae.encode(torch_img.to(vae.dtype).to(device)).latent_dist.sample(generator=generator)\n",
        "  return latents\n",
        "\n",
        "@torch.no_grad()\n",
        "def to_img(latents):\n",
        "  with autocast():\n",
        "    torch_img = vae.decode(latents.to(vae.dtype).to(device)).sample\n",
        "  torch_img = (torch_img / 2 + 0.5).clamp(0, 1)\n",
        "  np_img = torch_img.cpu().permute(0, 2, 3, 1).detach().numpy()[0]\n",
        "  np_img = (np_img * 255.0).astype(np.uint8)\n",
        "  img = Image.fromarray(np_img)\n",
        "  return img\n",
        "\n",
        "def resize_to_512(input_file, output_file):\n",
        "  img = Image.open(input_file).convert('RGB')\n",
        "  # Center cropped image\n",
        "  maxdim = max(img.width, img.height)\n",
        "  mindim = min(img.width, img.height)\n",
        "  left = max(0, (img.width - img.height) // 2 - 1)\n",
        "  top = max(0, (img.height - img.width) // 2 - 1)\n",
        "  img = img.crop((left, top, left + mindim - 1, top + mindim - 1))\n",
        "  # Resize\n",
        "  img = img.resize((512, 512), Image.LANCZOS)\n",
        "  img.save(output_file, lossless = True, quality = 100)\n",
        "\n",
        "def print_metrics(gt, img):\n",
        "  gt = np.array(gt)\n",
        "  img = np.array(img)\n",
        "  print('PSNR: {:.4f}'.format(get_psnr(gt, img)))\n",
        "  print('SSIM: {:.4f}'.format(get_ssim(gt, img, multichannel=True, \n",
        "                                       data_range=img.max() - img.min())))"
      ],
      "metadata": {
        "id": "6f7oLn4_ZhqG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Compression methods"
      ],
      "metadata": {
        "id": "ZvOvEBh3aaDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coeff = 0.18215\n",
        "\n",
        "def quantize(latents):\n",
        "  quantized_latents = (latents / (255 * coeff) + 0.5).clamp(0, 1)\n",
        "  quantized = quantized_latents.cpu().permute(0, 2, 3, 1).detach().numpy()[0]\n",
        "  quantized = (quantized * 255 + 0.5).astype(np.uint8)\n",
        "  return quantized\n",
        "\n",
        "def unquantize(quantized):\n",
        "  unquantized = quantized.astype(np.float32) / 255.0\n",
        "  unquantized = unquantized[None].transpose(0, 3, 1, 2)\n",
        "  unquantized_latents = (unquantized - 0.5) * (255 * coeff)\n",
        "  unquantized_latents = torch.from_numpy(unquantized_latents)\n",
        "  return unquantized_latents.to(device)\n",
        "\n",
        "@torch.no_grad()\n",
        "def denoise(latents):\n",
        "  latents = latents * coeff\n",
        "  step_size = 15 \n",
        "  n_inference_steps = scheduler.config.get('num_train_timesteps', 1000) // step_size\n",
        "  strength = 0.04\n",
        "  scheduler.set_timesteps(n_inference_steps)\n",
        "  offset = scheduler.config.get('steps_offset', 0)\n",
        "  init_timestep = int(n_inference_steps * strength) + offset\n",
        "  init_timestep = min(init_timestep, n_inference_steps)\n",
        "  timesteps = scheduler.timesteps[-init_timestep]\n",
        "  timesteps = torch.tensor([timesteps], dtype=torch.long, device=device)\n",
        "  extra_step_kwargs = {}\n",
        "  if 'eta' in set(inspect.signature(scheduler.step).parameters.keys()):\n",
        "    extra_step_kwargs['eta'] = 0.9\n",
        "  \n",
        "  latents = latents.to(unet.dtype).to(device)\n",
        "  t_start = max(n_inference_steps - init_timestep + offset, 0)\n",
        "  with autocast():\n",
        "    for i, t in enumerate(scheduler.timesteps[t_start:]):\n",
        "      noise_pred = unet(latents, t, encoder_hidden_states=uncond_embeddings).sample\n",
        "      latents = scheduler.step(noise_pred, t, latents, **extra_step_kwargs).prev_sample\n",
        "\n",
        "  scheduler.set_timesteps(1)\n",
        "  return latents / coeff\n",
        "\n",
        "def compress(input_file, output_path):\n",
        "  img = Image.open(input_file)\n",
        "  display(img)\n",
        "  print('Original')\n",
        "  print('Size: {:.2f} kB'.format(os.stat(input_file).st_size / 1024))\n",
        "\n",
        "  latents = to_latents(img)\n",
        "  img_from_latents = to_img(latents)\n",
        "  display(img_from_latents)\n",
        "  print('VAE roundtrip')\n",
        "  print_metrics(img, img_from_latents)\n",
        "\n",
        "  quantized = quantize(latents)\n",
        "  del latents\n",
        "  quantized_img = Image.fromarray(quantized)\n",
        "  quantized_img.save(output_path + '.webp', lossless=True, quality=100)\n",
        "\n",
        "  unquantized_latents = unquantize(quantized)\n",
        "  unquantized_img = to_img(unquantized_latents)\n",
        "  display(unquantized_img)\n",
        "  del unquantized_latents\n",
        "  print('VAE decoded from 8-bit quantized latents')\n",
        "  print_metrics(img, unquantized_img)\n",
        "\n",
        "  attr = liq.Attr()\n",
        "  attr.speed = 1\n",
        "  attr.max_colors = 256\n",
        "  input_img = attr.create_rgba(quantized.flatten('C').tobytes(),\n",
        "                               quantized_img.width, quantized_img.height, 0\n",
        "  )\n",
        "  quantization_result = input_img.quantize(attr)\n",
        "  quantization_result.dithering_level = 1.0\n",
        "  out_pixels = quantization_result.remap_image(input_img)\n",
        "  out_palette = quantization_result.get_palette()\n",
        "  indices = np.frombuffer(out_pixels, np.uint8)\n",
        "  palette = np.array([c for color in out_palette for c in color], dtype=np.uint8)\n",
        "\n",
        "  palettized_bytes = io.BytesIO()\n",
        "  np.savez_compressed(palettized_bytes, w=64, h=64, i=indices.flatten(), p=palette)\n",
        "  with open(output_path + '.npz', 'wb') as f:\n",
        "    f.write(palettized_bytes.getbuffer())\n",
        "\n",
        "  compressed_bytes = zlib.compress(\n",
        "      np.concatenate((palette, indices), dtype=np.uint8).tobytes(), level=9\n",
        "  )\n",
        "  with open(output_path + '.bin', 'wb') as f:\n",
        "    f.write(compressed_bytes)\n",
        "\n",
        "  sd_bytes = len(compressed_bytes)\n",
        "\n",
        "  indices = indices.reshape((64, 64))\n",
        "  palettized_latent_img = Image.fromarray(indices, mode='P')\n",
        "  palettized_latent_img.putpalette(palette, rawmode='RGBA')\n",
        "  latents = np.array(palettized_latent_img.convert('RGBA'))\n",
        "  latents = unquantize(latents)\n",
        "  palettized_img = to_img(latents)\n",
        "  display(palettized_img)\n",
        "  print('VAE decoding of palettized and dithered 8-bit latents')\n",
        "  print_metrics(img, palettized_img)\n",
        "\n",
        "  latents = denoise(latents)\n",
        "  denoised_img = to_img(latents)\n",
        "  display(denoised_img)\n",
        "  del latents\n",
        "  print('VAE decoding of de-noised dithered 8-bit latents')\n",
        "  print('Size: {:.2f} kB'.format(os.stat('/content/output/lena.bin').st_size / 1024))\n",
        "  print_metrics(img, denoised_img)\n",
        "\n",
        "  jpg_bytes = io.BytesIO()\n",
        "  q = 0 \n",
        "  while jpg_bytes.getbuffer().nbytes < sd_bytes:\n",
        "    jpg_bytes = io.BytesIO()\n",
        "    img.save(jpg_bytes, format='JPEG', quality=q, optimize=True, subsampling=1)\n",
        "    jpg_bytes.flush()\n",
        "    jpg_bytes.seek(0)\n",
        "    jpg_bytes = io.BytesIO(mozjpeg_lossless_optimization.optimize(jpg_bytes.read()))\n",
        "    jpg_bytes.flush()\n",
        "    q += 1\n",
        "\n",
        "  with open(output_path + '.jpg', 'wb') as f:\n",
        "    f.write(jpg_bytes.getbuffer())\n",
        "  \n",
        "  jpg = Image.open(jpg_bytes)\n",
        "  try:\n",
        "    display(jpg)\n",
        "    print('JPG comprassed with quality setting: {}'.format(q))\n",
        "    print('size: {:.2f} kB'.format(jpg_bytes.getbuffer().nbytes / 1024))\n",
        "    print_metrics(img, jpg)\n",
        "  except:\n",
        "    print('Sth went wrong compressing {}.jpg'.format(output_path))\n",
        "\n",
        "  webp_bytes = io.BytesIO()\n",
        "  q = 0\n",
        "  while webp_bytes.getbuffer().nbytes < sd_bytes:\n",
        "    webp_bytes = io.BytesIO()\n",
        "    img.save(webp_bytes, format='WEBP', quality=q, method=6)    \n",
        "    webp_bytes.flush()\n",
        "    q += 1\n",
        "\n",
        "  with open(output_path + '.webp', 'wb') as f:\n",
        "    f.write(webp_bytes.getbuffer())\n",
        "  try:\n",
        "    webp = Image.open(webp_bytes)\n",
        "    display(webp)\n",
        "    print('WebP compressed with quality setting: {}'.format(q))\n",
        "    print('size: {:.2f} kB'.format(webp_bytes.getbuffer().nbytes / 1024))\n",
        "    print_metrics(img, webp)\n",
        "  except:\n",
        "    print('Sth went wrong compressing {}.webp'.format(output_path))"
      ],
      "metadata": {
        "id": "lwZLClZ2Zndx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import shutil\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "rescaled_dir = input_dir + '/rescaled/'\n",
        "\n",
        "if not os.path.isdir(rescaled_dir):\n",
        "  os.mkdir(rescaled_dir)\n",
        "\n",
        "print('Rescaling images to 512x512')\n",
        "for i, filename in tqdm(enumerate(os.listdir(input_dir))):\n",
        "  f_in = os.path.join(input_dir, filename)\n",
        "  f_out = os.path.join(rescaled_dir, os.path.splitext(filename)[0] + '.png')\n",
        "  if os.path.isfile(f_in) and not os.path.isfile(f_out):\n",
        "    try:\n",
        "      resize_to_512(f_in, f_out)\n",
        "    except:\n",
        "      print('Skipping {} beacuse the file could not be opened.'.format(filename))\n",
        "\n",
        "if os.path.isdir(output_dir):\n",
        "  shutil.rmtree(output_dir)\n",
        "os.mkdir(output_dir)\n",
        "for filename in os.listdir(rescaled_dir):\n",
        "  f = os.path.join(rescaled_dir, filename)\n",
        "  if os.path.isfile(f):\n",
        "    compress(f, os.path.splitext(os.path.join(output_dir, filename))[0])\n",
        "    time.sleep(0.1)"
      ],
      "metadata": {
        "id": "UQA80tiL7rbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "filename = 'lena'\n",
        "fig = plt.figure(figsize=(20, 5))\n",
        "\n",
        "fig.add_subplot(2, 2, 1)\n",
        "plt.imshow(plt.imread(input_dir + filename + '.png'))\n",
        "plt.axis('off')\n",
        "plt.title('Original')\n",
        "\n",
        "fig.add_subplot(1, 4, 2)\n",
        "plt.imshow(plt.imread(output_dir + filename + '.jpg'))\n",
        "plt.axis('off')\n",
        "plt.title('JPG (5.41 kB)')\n",
        "\n",
        "fig.add_subplot(1, 4, 3)\n",
        "plt.imshow(plt.imread(output_dir + filename + '.webp'))\n",
        "plt.axis('off')\n",
        "plt.title('WebP (5.16 kB)')\n",
        "\n",
        "fig.add_subplot(1, 4, 4)\n",
        "plt.imshow(plt.imread(output_dir + filename + '.webp'))\n",
        "plt.axis('off')\n",
        "plt.title('Stable Diffusion (4.97 kB)')"
      ],
      "metadata": {
        "id": "-ZHd0FTGw-s6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}