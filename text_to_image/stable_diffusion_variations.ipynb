{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMC9V6upGtUSr2g4iZyU/3C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PsorTheDoctor/Sekcja-SI/blob/master/modern_approach/text_to_image/stable_diffusion_variations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stable Diffusion variations"
      ],
      "metadata": {
        "id": "xNeiOvYLGGU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_NRdm3uEn9E"
      },
      "outputs": [],
      "source": [
        "!git clone https://huggingface.co/spaces/lambdalabs/stable-diffusion-image-variations\n",
        "%cd stable-diffusion-image-variations/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "zcrh-6GXGWt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from PIL import Image\n",
        "from lambda_diffusers import StableDiffusionImageEmbedPipeline\n",
        "\n",
        "device = 'cuda'\n",
        "pipe = StableDiffusionImageEmbedPipeline.from_pretrained(\n",
        "    \"lambdalabs/sd-image-variations-diffusers\",\n",
        "    revision=\"273115e88df42350019ef4d628265b8c29ef4af5\"\n",
        ")\n",
        "pipe = pipe.to(device)\n",
        "\n",
        "def main(input, scale=3.0, n_samples=4, steps=25, seed=0):\n",
        "\n",
        "  generator = torch.Generator(device=device).manual_seed(int(seed))\n",
        "\n",
        "  images_list = pipe(\n",
        "      n_samples * [input],\n",
        "      guidance_scale=scale,\n",
        "      n_inference_steps=steps,\n",
        "      generator=generator\n",
        "  )\n",
        "  images = []\n",
        "  for i, img in enumerate(images_list['sample']):\n",
        "    if images_list['nsfw_content_detected'][i]:\n",
        "      safe_img = Image.open(r'unsafe.png')\n",
        "      images.append(safe_img)\n",
        "    else:\n",
        "      images.append(img)\n",
        "  \n",
        "  return images\n",
        "\n",
        "inputs = [\n",
        "    gr.Image(),\n",
        "    gr.Slider(0, 25, value=3, step=1, label='Guidance scale'),\n",
        "    gr.Slider(1, 4, value=1, step=1, label='Number images'),\n",
        "    gr.Slider(5, 50, value=25, step=5, label='Steps'),\n",
        "    gr.Number(0, label='Seed', precision=0)\n",
        "]\n",
        "output = gr.Gallery(label='Generated variations')\n",
        "output.style(grid=2)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=main, \n",
        "    title='Image variations',\n",
        "    inputs=inputs,\n",
        "    outputs=output\n",
        ")\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "44_dfOEtTSin"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}